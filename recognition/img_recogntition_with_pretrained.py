# -*- coding: utf-8 -*-
"""img_recogntition_with_pretrained.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cGrPp7D4RKOiM_88DXIXymkS0U8Yam4b
"""

from matplotlib import pyplot as plt
import numpy as np
import imghdr
import cv2
import keras
import os
import tensorflow as tf
from keras import layers, regularizers

data_dir = "data"
exts = ["jpg", "jpeg", "JPEG", "png"]

for dir in os.listdir(data_dir):
  for img in os.listdir(os.path.join(data_dir, dir)):
            img_path = os.path.join(data_dir, dir, img)
            try:
                tip = imghdr.what(img_path)
                if tip not in exts:
                    os.remove(img_path)
            except Exception as e:
                print(f'failed to remove {img_path}')

# Load the image dataset
data = tf.keras.preprocessing.image_dataset_from_directory(
    "data",
    image_size=(224, 224),
    shuffle=True
)

data_len = len(data)

train = data.take(int(data_len*0.8))
val = data.skip(int(data_len*0.8)).take(int(data_len*0.2))

data_augmentation = keras.Sequential([
    layers.RandomFlip('horizontal'),
    layers.RandomRotation(0.3),
    layers.RandomZoom(0.3),
    layers.RandomContrast(0.3),
])

data = data.map(lambda x, y: (x / 255, y))
batch_iterator = data.as_numpy_iterator()
batch = data.as_numpy_iterator().next()
fig, ax = plt.subplots(ncols=6, figsize=(10, 10))
plt.axis('off')
for idx, img in enumerate(batch[0][:6]):
    ax[idx].imshow(img)
    ax[idx].title.set_text(batch[1][idx])

conventx_pretrained_model = keras.applications.ConvNeXtXLarge(weights="imagenet", include_top=False, input_shape=(224,224,3))

for layer in conventx_pretrained_model.layers:
    layer.trainable = False

model = keras.Model(inputs=conventx_pretrained_model.input, outputs=conventx_pretrained_model.output)

model_output = layers.Conv2D(64, (3,3), activation="relu", kernel_regularizer=regularizers.l2(0.01))(model.output)
model_output = layers.MaxPooling2D(2,2)(model_output)
model_output = layers.BatchNormalization()(model_output)

model_output = layers.Flatten()(model_output)

model_output = layers.Dense(32, activation="relu")(model_output)
model_output = layers.Dropout(0.3)(model_output)
model_output = layers.Dense(2, activation="softmax")(model_output)

model = keras.Model(inputs=conventx_pretrained_model.input, outputs=model_output)

model.compile(optimizer=tf.keras.optimizers.Adamax(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])

tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='logs')
early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor="loss",
    patience=5,
    restore_best_weights=True,
)

hist = model.fit(train,epochs=3, validation_data=val, callbacks=[tensorboard_callback, early_stopping])

fig = plt.figure()
plt.plot(hist.history['loss'], color='red', label='loss')
plt.plot(hist.history['val_loss'], color='orange', label='val_loss')
fig.suptitle('Loss', fontsize=16)
plt.legend(loc='upper left')
plt.show()

fig = plt.figure()
plt.plot(hist.history['accuracy'], color='red', label='accuracy')
plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')
fig.suptitle('Accuracy', fontsize=20)
plt.legend(loc="upper left")
plt.show()

img = cv2.imread('ok1.jpg')
plt.imshow(img)
plt.show()

res =  tf.image.resize(img, (224,224))

yhat = model.predict(np.expand_dims(res/255,0))

print(yhat)

class_label = np.argmax(yhat)
confidence = np.max(yhat)
print(f"Class label: {class_label}, Confidence: {confidence:.2f}")